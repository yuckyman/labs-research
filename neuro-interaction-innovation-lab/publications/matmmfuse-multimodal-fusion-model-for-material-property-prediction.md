---
title: "MatMMFuse: Multimodal fusion model for material property prediction"
authors:
  - "Abhiroop Bhattacharya"
  - "Sylvain G Cloutier"
year: 2025
journal: "Machine Learning: Science and Technology"
doi: "10.1088/2632-2153/ae1927"
url: "https://doi.org/10.1088/2632-2153/ae1927"
lab: "neuro-interaction-innovation-lab"
faculty:
  - "Sylvia Bhattacharya"
tags:
  - "publication"
  - "neuro-interaction-innovation-lab"
abstract: |
  <jats:title>Abstract</jats:title>
                    <jats:p>The recent progress of using graph based encoding of crystal structures for high throughput material property prediction has been quite successful. However, using a single modality model prevents us from exploiting the advantages of an enhanced features space by combining different representations. Specifically, pre-trained Large language models can encode a large amount of knowledge which is beneficial for training of models. Moreover, the graph encoder is able to learn the local features while the text encoder is able to learn global information such as space group and crystal symmetry. In this work, we propose Material MultiModal fusion, a fusion based model which uses a multi-head attention mechanism for the combination of structure aware embedding from the crystal graph convolution network (CGCNN) and text embeddings from the SciBERT model. We train our model in an end-to-end framework using data from the materials project dataset. We show that our proposed model shows an improvement compared to the vanilla CGCNN and SciBERT model for all four key properties-formation energy, band gap, energy above hull and Fermi energy. Specifically, we observe an improvement of 40% compared to the vanilla CGCNN model and 68% compared to the SciBERT model for predicting the formation energy per atom. Importantly, we demonstrate the zero shot performance of the trained model on small curated datasets of Perovskites, Chalcogenides and the joint automated repository for various integrated simulation dataset. The results show that the proposed model exhibits better zero shot performance than the individual plain vanilla CGCNN and SciBERT model. This enables researchers to deploy the model for specialized industrial applications where collection of training data is prohibitively expensive.</jats:p>
fulltext_available: false
fulltext_source: "none"
created: "2025-12-01T09:35:16.136687"
---

# MatMMFuse: Multimodal fusion model for material property prediction

## Abstract

<jats:title>Abstract</jats:title>
                  <jats:p>The recent progress of using graph based encoding of crystal structures for high throughput material property prediction has been quite successful. However, using a single modality model prevents us from exploiting the advantages of an enhanced features space by combining different representations. Specifically, pre-trained Large language models can encode a large amount of knowledge which is beneficial for training of models. Moreover, the graph encoder is able to learn the local features while the text encoder is able to learn global information such as space group and crystal symmetry. In this work, we propose Material MultiModal fusion, a fusion based model which uses a multi-head attention mechanism for the combination of structure aware embedding from the crystal graph convolution network (CGCNN) and text embeddings from the SciBERT model. We train our model in an end-to-end framework using data from the materials project dataset. We show that our proposed model shows an improvement compared to the vanilla CGCNN and SciBERT model for all four key properties-formation energy, band gap, energy above hull and Fermi energy. Specifically, we observe an improvement of 40% compared to the vanilla CGCNN model and 68% compared to the SciBERT model for predicting the formation energy per atom. Importantly, we demonstrate the zero shot performance of the trained model on small curated datasets of Perovskites, Chalcogenides and the joint automated repository for various integrated simulation dataset. The results show that the proposed model exhibits better zero shot performance than the individual plain vanilla CGCNN and SciBERT model. This enables researchers to deploy the model for specialized industrial applications where collection of training data is prohibitively expensive.</jats:p>

## Links

- DOI: [10.1088/2632-2153/ae1927](https://doi.org/10.1088/2632-2153/ae1927)
- URL: [Link](https://doi.org/10.1088/2632-2153/ae1927)

## Faculty

- [[neuro-interaction-innovation-lab/faculty#sylvia-bhattacharya|Sylvia Bhattacharya]]
